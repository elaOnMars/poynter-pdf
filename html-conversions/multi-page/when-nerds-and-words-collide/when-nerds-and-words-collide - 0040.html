<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="FineReader"/><link rel="stylesheet" href="when-nerds-and-words-collide - 0040_files/when-nerds-and-words-collide - 0040.css" type="text/css"/>
</head>
<body><h3><a name="bookmark0"></a><span class="font4">Driving Defensively Through Data’s Dangers</span></h3>
<p><span class="font1" style="font-weight:bold;">By Dwight Morris</span></p>
<p><span class="font3">For 18 of the past 22 years I have struggled to merge traditional reporting with in-depth data analysis. Plucked from graduate school in 1977 by </span><span class="font3" style="font-style:italic;">The New York Times</span><span class="font3"> to help an aging, irascible,&nbsp;and, to my mind, brilliant editor named Henry Lieberman bring&nbsp;what was then known as “precision journalism” to the paper,&nbsp;much of my career has been devoted to the design and execution&nbsp;of large data-driven investigative projects. Along the way I have&nbsp;been fortunate to have a hand in the development of one Pulitzer&nbsp;Prize winner at the </span><span class="font3" style="font-style:italic;">Journal-Constitution</span><span class="font3"> in Atlanta and a second&nbsp;Pulitzer finalist at the </span><span class="font3" style="font-style:italic;">Los Angeles Times.</span></p>
<p><span class="font3">If there is one thing I can say with absolute certainty, it is that I despise the phrase “computer assisted reporting,” hereafter&nbsp;grudgingly referred to as CAR. My loathing of the phrase springs&nbsp;from the fact that its continued use serves to over-emphasize the&nbsp;importance of machines and software while largely ignoring the&nbsp;truly important factors that determine the success of any CAR&nbsp;project - critical thinking about one’s analysis plan and the ability to recognize and fix data problems before they become the&nbsp;subject of a retraction.</span></p>
<p><span class="font3">Truth be told, I’m also not that wild about the phrase “precision journalism.” It strikes me as an unintentional slap at those who are not terribly computer literate but who nevertheless do&nbsp;their utmost to be precise at all times. As an alternative to both&nbsp;these labels, I offer the term “data-based reporting,” which places&nbsp;the emphasis where I believe it belongs - on understanding and&nbsp;explaining the mountains of information routinely used by government agencies at all levels in ways that impact public life. If as&nbsp;journalists you do nothing else, at least consider the following intellectual roadmap for getting started.</span></p><h4><a name="bookmark1"></a><span class="font2" style="font-weight:bold;">Recognize that data are always dirty</span></h4>
<p><span class="font3">The first step in becoming a good data-based reporter is to recognize that we are largely powerless over those who&nbsp;construct and provide data. Databases are built to specifications&nbsp;that meet the needs of a particular government agency, which&nbsp;may or may not suit our reportorial needs. Among the linchpins&nbsp;in this database building process are data-entry operators who&nbsp;frequently know little about and could not care less about what&nbsp;they are keying. Their productivity, and therefore then job performance, is measured by how many keystrokes per hour they&nbsp;produce on average.</span></p>
<p><span class="font3">As a result, if there is one thing you can be sure of, it is that all databases are dirty. As I write this, the Federal Election Commission’s campaign contribution database contains roughly&nbsp;$2 million more in soft money donations to the 1998 Republican&nbsp;House-Senate Dinner Committee than it should. A data-entry&nbsp;operator either ignored or misunderstood how memo entries&nbsp;should be handled and, as a result, double-keyed dozens of contributions. That error has gone unnoticed by the FEC for more&nbsp;than six months.</span></p>
<p><span class="font3">Far from being the exception, this is the unfortunate norm. Once errors are pointed out or discovered, the FEC takes fairly</span></p>
<p><span class="font3">swift action to correct them, but over the past year literally thousands of factual errors, both large and small, have been corrected at one point or another. If you happen to be one of the hundreds&nbsp;of journalists who uses the data for primary research on stories&nbsp;each year, you had better have a sufficient understanding of the&nbsp;rules governing contributions to spot potential errors and fix&nbsp;them.</span></p>
<p><span class="font3">Whether any error in the FEC data is significant beyond the natural journalistic desire for complete accuracy depends largely&nbsp;upon whether one is writing about how much a particular&nbsp;committee or candidate raised or writing about how much soft&nbsp;money was raised by all party committees. In general, data&nbsp;problems are most acute when one is writing about a restricted&nbsp;“universe;” the smaller the focus of the story, the more critical&nbsp;the need for correcting even small errors.</span></p>
<p><span class="font3">For example, following each of the past four election cycles I have examined federal donation records to determine how many&nbsp;Americans violated the $25,000 annual limit on contributions&nbsp;imposed as part of the post-Watergate reforms. While there have&nbsp;been well over 150 individuals who appeared to be in violation&nbsp;of federal contribution limits in each of the last two election&nbsp;cycles, roughly 25 percent of those scofflaws proved to be false&nbsp;positives due to reporting errors by party and candidate committees, as well as data entry errors by the FEC.</span></p>
<p><span class="font3">During the 1992 election cycle, three members of one Chicago family appeared over the limit until we discovered that&nbsp;the National Republican Senatorial Committee had inadvertently filed three copies of the same page of one of its reports. The&nbsp;FEC dutifully keyed all the pages it received without noticing&nbsp;the duplicate page numbers.</span></p>
<p><span class="font3">As a result, a single $10,000 donation by each of the three individuals appeared in the FEC database as three $10,000 donations by each. Without rigid rules dictating that we double&nbsp;check all donations attributed to our targets, we easily could&nbsp;have branded three innocent people on the front page of the </span><span class="font3" style="font-style:italic;">Los&nbsp;Angeles Times.</span></p><h4><a name="bookmark2"></a><span class="font2" style="font-weight:bold;">Recognize that data you need may be missing</span></h4>
<p><span class="font3">Lest one believe that the FEC is particularly incompetent, consider the case of the Resolution Trust Corporation (RTC), the&nbsp;now-defunct agency set up to dispose of assets originally held&nbsp;by failed savings and loans. In August 1991, Bob Rosenblatt, a&nbsp;reporter in the </span><span class="font3" style="font-style:italic;">Los Angeles Times’</span><span class="font3"> Washington bureau, and I&nbsp;decided to assess the performance of the RTC in recouping for</span></p><div><img src="when-nerds-and-words-collide - 0040_files/when-nerds-and-words-collide - 0040-1.jpg" style="width:64pt;height:84pt;"/>
<p><span class="font0">Dwight L. Morris is president of Campaign Study Group (CSG), a for-profit media consulting firm&nbsp;specializing in campaign finance analysis. During&nbsp;the 1996 and 1998 campaigns, he wrote Money&nbsp;Talk$, a column on campaign finance for wash-ingtonpost.com. For six years prior to founding&nbsp;CSG, Morris was editor for special investigations&nbsp;at the </span><span class="font0" style="font-style:italic;">Los Angeles Times'</span><span class="font0"> Washington bureau,&nbsp;where he designed numerous CAR projects.</span></p></div><br clear="all"/><div>
<p><span class="font1" style="font-weight:bold;">35</span></p></div><br clear="all"/>
</body>
</html>